{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed572069-bd4a-4483-9609-1bbf34cd56da",
   "metadata": {},
   "source": [
    "# Exercício 1: Bernoulli e Uniforme\n",
    "\n",
    "1. Implemente uma função que gere uma realização de uma variável de Bernoulli com parâmetro $p$.\n",
    "\n",
    "2. Usando $p = 0.5$, implemente um gerador de variáveis **Uniformes(0,1)** a partir da expansão binária:\n",
    "\n",
    "   $$\n",
    "   U = \\sum_{k=1}^m \\frac{B_k}{2^k}, \\quad B_k \\sim \\text{Bernoulli}(0.5).\n",
    "   $$\n",
    "\n",
    "   Gere uma amostra de tamanho $1000$ para $U$, utilizando $m$ bits de precisão (por exemplo, $m = 20$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d9ac0e-ecb1-4525-8c30-610fe7e2d3d9",
   "metadata": {},
   "source": [
    "# Exercício 2: Binomial\n",
    "\n",
    "Implemente um gerador de variáveis aleatórias com distribuição Binomial($n,p$) utilizando **dois métodos diferentes**:\n",
    "\n",
    "1. **Método via Bernoullis**: some $n$ variáveis independentes $B_i \\sim \\text{Bernoulli}(p)$.\n",
    "\n",
    "2. **Método via inversão recursiva**: utilize a função de distribuição acumulada da Binomial e um gerador uniforme para determinar o valor da variável.\n",
    "\n",
    "3. Compare o **tempo de execução** dos dois métodos ao gerar uma amostra de tamanho grande (por exemplo, $10^5$ observações).  \n",
    "   - Fixe $n$ (por exemplo, $n=20$) e varie o valor de $p$ (por exemplo, $p=0.1, 0.3, 0.5, 0.7, 0.9$).  \n",
    "   - Observe como o desempenho dos dois métodos se altera de acordo com $p$.\n",
    "\n",
    "4. Compare as **densidades empíricas** obtidas pelos dois métodos com a densidade de referência gerada pela função pronta `numpy.random.binomial`.  \n",
    "   - Faça histogramas normalizados ou gráficos de barras lado a lado.  \n",
    "   - Discuta se as distribuições coincidem e se há diferenças relevantes.\n",
    "\n",
    "5. No caso do **método de inversão recursiva**, calcule o **número médio de passos** que o algoritmo dá até parar.  \n",
    "   - Mostre empiricamente esse valor para diferentes $p$.  \n",
    "   - Compare com a expectativa teórica $$\\mathbb{E}[\\text{nº de passos}] = np + 1.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2316b6-89db-466a-bec2-0136d7954be4",
   "metadata": {},
   "source": [
    "# Exercício 3: Poisson\n",
    "\n",
    "Implemente um gerador de variáveis aleatórias com distribuição Poisson($\\lambda$) utilizando **dois métodos**:\n",
    "\n",
    "1. **Versão recursiva do algoritmo de inversão** (vista em aula).  \n",
    "2. **Versão melhorada** (já apresentada nas notas).  \n",
    "\n",
    "3. Compare os **tempos de execução** dos dois métodos para diferentes valores de $\\lambda$ (por exemplo, $\\lambda = 1, 5, 10, 50, 100$) e discuta em quais situações cada método é mais eficiente.\n",
    "\n",
    "4. Considere agora $\\lambda = 500$.  \n",
    "   - Simule uma amostra de variáveis Poisson($\\lambda$).  \n",
    "   - Compare o histograma obtido com a densidade de uma Normal $N(\\lambda, \\lambda)$, plotando a curva normal com a função `scipy.stats.norm.pdf` ou `numpy` equivalente.  \n",
    "\n",
    "5. No algoritmo melhorado, o número de passos necessários para encontrar o valor sorteado é dado por\n",
    "   $$\n",
    "   T = 1 + |X - \\lambda|, \\quad X \\sim \\text{Poisson}(\\lambda).\n",
    "   $$\n",
    "   (a) Usando a aproximação $X \\approx N(\\lambda, \\lambda)$, mostre que\n",
    "   $$\n",
    "   \\mathbb{E}[T] \\;\\approx\\; 1 + \\sqrt{\\lambda}\\,\\mathbb{E}[|N|],\n",
    "   $$\n",
    "   onde $N \\sim N(0,1)$.  \n",
    "   (b) Calcule $\\mathbb{E}[|N|]$ e conclua que\n",
    "   $$\n",
    "   \\mathbb{E}[T] \\;\\approx\\; 1 + \\sqrt{\\tfrac{2\\lambda}{\\pi}}.\n",
    "   $$\n",
    "   (c) Para $\\lambda = 500$, estime empiricamente o valor médio de $T$ a partir de simulações e compare com a fórmula aproximada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb62f46-3170-4108-827b-f2c585ba5dab",
   "metadata": {},
   "source": [
    "# Exercício 4: Geométrica\n",
    "\n",
    "1. Implemente um gerador de variáveis aleatórias com distribuição Geométrica($p$) utilizando **dois métodos**:\n",
    "\n",
    "   - **Versão ingênua (naive):** gerar sucessivamente variáveis Bernoulli($p$) até obter o primeiro sucesso;\n",
    "   - **Versão via inversão:** usando $U \\sim \\text{Uniforme}(0,1)$, calcule\n",
    "     $$\n",
    "     X = \\left\\lfloor \\frac{\\log(1-U)}{\\log(1-p)} \\right\\rfloor + 1.\n",
    "     $$\n",
    "\n",
    "2. Para um valor fixo de $p$ (por exemplo, $p = 0.3$), gere uma amostra de tamanho $10^5$ utilizando ambos os métodos.\n",
    "\n",
    "3. Compare o **tempo de execução** dos dois métodos e discuta qual é mais eficiente.\n",
    "\n",
    "4. Compare também as **densidades empíricas** obtidas com a distribuição gerada pela função `numpy.random.geometric` (ajustada para contar o número de falhas antes do sucesso).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2ea17b-625a-4079-b63d-9e868e479c42",
   "metadata": {},
   "source": [
    "# Exercício 5: Binomial Negativa\n",
    "\n",
    "1. Implemente um gerador de variáveis aleatórias com distribuição $\\mathrm{NegBin}(r,p)$ (número de **ensaios até o $r$-ésimo sucesso**) utilizando **três métodos**:\n",
    "\n",
    "   - **Versão soma de Bernoullis:** simule sucessivos ensaios $B_i \\sim \\mathrm{Bernoulli}(p)$ até acumular $r$ sucessos.  \n",
    "     O número total de ensaios realizados corresponde ao valor de $X$.\n",
    "\n",
    "   - **Versão soma de geométricas:** gere $r$ variáveis $X_i \\sim \\text{Geom}(p)$ via inversão,\n",
    "     $$\n",
    "     X_i = \\left\\lfloor \\frac{\\log(1-U_i)}{\\log(1-p)} \\right\\rfloor + 1, \n",
    "     \\quad U_i \\sim \\text{Uniforme}(0,1),\n",
    "     $$\n",
    "     e defina\n",
    "     $$\n",
    "     X = X_1 + \\cdots + X_r.\n",
    "     $$\n",
    "\n",
    "   - **Versão via inversão recursiva:** use $U \\sim \\text{Uniforme}(0,1)$, inicialize $n=r$, $p_r = p^r$, $F = p_r$, e atualize\n",
    "     $$\n",
    "     p_{n+1} = p_n \\cdot \\frac{n}{\\,n-r+1\\,}(1-p), \n",
    "     \\qquad F \\leftarrow F + p_{n+1},\n",
    "     $$\n",
    "     até encontrar o menor $n$ tal que $F \\ge U$.\n",
    "\n",
    "2. Para valores fixos de $r$ e $p$ (por exemplo, $r=5$, $p=0.3$), gere uma amostra de tamanho $10^5$ utilizando os três métodos.\n",
    "\n",
    "3. Compare os resultados com a função `numpy.random.negative_binomial(r, p)` **corrigida para ensaios**:\n",
    "   $$\n",
    "   X_{\\text{NumPy}} = Y_{\\text{NumPy}} + r,\n",
    "   $$\n",
    "   onde `numpy.random.negative_binomial(r, p)` retorna $Y$ = número de falhas antes do $r$-ésimo sucesso.\n",
    "\n",
    "4. Faça gráficos das distribuições empíricas dos quatro métodos e compare com a **PMF teórica**.\n",
    "\n",
    "5. Compare também o **tempo de execução** dos três métodos de simulação (soma de Bernoullis, soma de geométricas, inversão recursiva) para diferentes valores de $r$ (ex.: $r=5,20$) e $p$ (ex.: $0.1, 0.3, 0.5, 0.7, 0.9$). Discuta como $r$ e $p$ afetam a eficiência de cada método.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e51dd1-ea41-4bb4-bddc-e49c09e463da",
   "metadata": {},
   "source": [
    "# Exercício 4: Hipergeométrica\n",
    "\n",
    "Implemente um gerador de variáveis aleatórias $X \\sim \\text{Hipergeom}(N,K,n)$ utilizando o **algoritmo de Fisher–Yates parcial** para realizar a amostragem sem reposição.  \n",
    "Compare o histograma da amostra simulada com a distribuição teórica dada por `scipy.stats.hypergeom.pmf`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
